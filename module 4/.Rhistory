# Calculate misclassification rate for the test set
test_misclass_rate <- missClass(testSA$chd, test_pred)
print(paste("Misclassification Rate on Test Set:", test_misclass_rate))
# Install and load necessary library
library(ElemStatLearn)
# Load the South Africa Heart Disease Data
data(SAheart)
# Create training and test sets
set.seed(8484)
train = sample(1:dim(SAheart)[1], size = dim(SAheart)[1] / 2, replace = FALSE)
trainSA = SAheart[train, ]
testSA = SAheart[-train, ]
# Fit a logistic regression model
set.seed(13234)
logistic_model <- glm(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA,
family = "binomial")
# Make predictions on the training and test sets
train_pred <- predict(logistic_model, newdata = trainSA, type = "response")
test_pred <- predict(logistic_model, newdata = testSA, type = "response")
# Define the misclassification function
missClass <- function(values, prediction) {
sum(((prediction > 0.5) * 1) != values) / length(values)
}
# Calculate misclassification rate for the training set
train_misclass_rate <- missClass(trainSA$chd, train_pred)
print(paste("Misclassification Rate on Training Set:", train_misclass_rate))
# Calculate misclassification rate for the test set
test_misclass_rate <- missClass(testSA$chd, test_pred)
print(paste("Misclassification Rate on Test Set:", test_misclass_rate))
library(ElemStatLearn)
data(SAheart)
set.seed(13234)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
logit_model = glm(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data=trainSA, family="binomial")
missClass = function(values, prediction) {
sum(((prediction > 0.5) * 1) != values) / length(values)
}
train_predictions = predict(logit_model, type="response")
train_misclassification_rate = missClass(trainSA$chd, train_predictions)
test_predictions = predict(logit_model, newdata=testSA, type="response")
test_misclassification_rate = missClass(testSA$chd, test_predictions)
cat("Misclassification rate on the training set:", train_misclassification_rate, "\n")
cat("Misclassification rate on the test set:", test_misclassification_rate, "\n")
# Install the ElemStatLearn package if you haven't already
# Load the library and the dataset
library(ElemStatLearn)
data(SAheart)
# Set the seed for reproducibility
set.seed(8484)
# Create training and test sets
train = sample(1:dim(SAheart)[1], size = dim(SAheart)[1] / 2, replace = FALSE)
trainSA = SAheart[train, ]
testSA = SAheart[-train, ]
# Set the seed for the logistic regression model
set.seed(13234)
# Fit a logistic regression model
logistic_model <- glm(chd ~ age + alcohol + obesity + tobacco + typeA + ldl,
data = trainSA,
family = "binomial")
# Load the necessary libraries
library(ElemStatLearn)
library(randomForest)
library(caret)
# Load the data
data(vowel.train)
data(vowel.test)
# Set the target variable y as a factor
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
# Set seed for reproducibility
set.seed(33833)
# Fit a random forest model
rf_model <- randomForest(y ~ ., data = vowel.train)
# Calculate variable importance using Gini importance
var_importance <- varImp(rf_model)
# Print the order of variable importance
print(var_importance)
View(vowel.train)
library(caret)
library(randomForest)
library(gbm)
install.packages("gbm")
library(gbm)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
rf_model <- train(y ~ ., data = vowel.train, method = "rf")
View(rf_model)
gbm_model <- train(y ~ ., data = vowel.train, method = "gbm", verbose = FALSE)
rf_pred <- predict(rf_model, newdata = vowel.test)
gbm_pred <- predict(gbm_model, newdata = vowel.test)
rf_pred
gbm_pred
# Calculate accuracy for random forest
rf_accuracy <- confusionMatrix(rf_pred, vowel.test$y)$overall['Accuracy']
# Calculate accuracy for boosted model
gbm_accuracy <- confusionMatrix(gbm_pred, vowel.test$y)$overall['Accuracy']
agree_indices <- rf_pred == gbm_pred
agree_accuracy <- confusionMatrix(rf_pred[agree_indices], vowel.test$y[agree_indices])$overall['Accuracy']
# Output the accuracies
rf_accuracy
gbm_accuracy
agree_accuracy
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(testing)
rf_model <- train(y ~ ., data = vowel.train, method = "rf")
set.seed(62433)
fit_rf <- train(diagnosis ~ ., data = training, method = "rf")
fit_gbm <- train(diagnosis ~ ., data = training, method = "gbm", verbose = FALSE)
fit_lda <- train(diagnosis ~ ., data = training, method = "lda")
stacked_data <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
pred_rf <- predict(fit_rf, testing)
pred_gbm <- predict(fit_gbm, testing)
pred_lda <- predict(fit_lda, testing)
stacked_data <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
set.seed(62433)
stacked_rf <- train(diagnosis ~ ., data = stacked_data, method = "rf")
stacked_pred <- predict(stacked_rf, stacked_data)
accuracy_rf <- confusionMatrix(pred_rf, testing$diagnosis)$overall['Accuracy']
accuracy_gbm <- confusionMatrix(pred_gbm, testing$diagnosis)$overall['Accuracy']
accuracy_lda <- confusionMatrix(pred_lda, testing$diagnosis)$overall['Accuracy']
accuracy_stacked <- confusionMatrix(stacked_pred, testing$diagnosis)$overall['Accuracy']
accuracy_rf
accuracy_gbm
accuracy_lda
accuracy_stacked
set.seed(3523)
# Load necessary libraries
library(AppliedPredictiveModeling)
library(caret)
library(glmnet)
install.packages("glmnet")
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
library(glmnet)
# Load the concrete data
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
# Prepare the data for glmnet
x <- as.matrix(training[, -ncol(training)])  # All predictors
y <- training$CompressiveStrength           # Outcome variable
View(x)
View(y)
View(testing)
set.seed(233)
lasso_model <- glmnet(x, y, alpha = 1)
View(logit_model)
View(lasso_model)
plot(lasso_model, xvar = "lambda")
coef(lasso_model)
View(lasso_model)
lambda_values <- lasso_model$lambda
coefficients <- as.matrix(coef(lasso_model))
# Define colors for each predictor
colors <- rainbow(ncol(coefficients) - 1)  # ncol(coefficients) - 1 (exclude intercept)
# Plot the coefficient paths manually
plot(log(lambda_values), coefficients[2, ], type = "n", xlab = "Log(Lambda)", ylab = "Coefficients",
main = "Lasso Coefficient Paths Colored by Predictor")
# Plot lines for each predictor with different colors
for (i in 2:nrow(coefficients)) {
lines(log(lambda_values), coefficients[i, ], col = colors[i-1], lwd = 2)
}
# Add a legend to map colors to predictors
legend("topright", legend = rownames(coefficients)[-1], col = colors, lwd = 2)
# Define colors for each predictor (excluding the intercept)
colors <- rainbow(ncol(coefficients) - 1)  # Generate different colors
# Plot the coefficient paths
plot(log(lambda_values), coefficients[2, ], type = "n", xlab = "Log(Lambda)", ylab = "Coefficients",
main = "Lasso Coefficient Paths Colored by Predictor")
# Add lines for each predictor (starting from 2 because the first is the intercept)
for (i in 2:nrow(coefficients)) {
lines(log(lambda_values), coefficients[i, ], col = colors[i - 1], lwd = 2)
}
# Add a legend to map colors to predictors
legend("topright", legend = rownames(coefficients)[-1], col = colors, lwd = 2)
colors <- terrain.colors(ncol(coefficients) - 1)  # Generate different colors
# Plot the coefficient paths
plot(log(lambda_values), coefficients[2, ], type = "n", xlab = "Log(Lambda)", ylab = "Coefficients",
main = "Lasso Coefficient Paths Colored by Predictor")
# Add lines for each predictor (starting from 2 because the first is the intercept)
for (i in 2:nrow(coefficients)) {
lines(log(lambda_values), coefficients[i, ], col = colors[i - 1], lwd = 2)
}
# Add a legend to map colors to predictors
legend("topright", legend = rownames(coefficients)[-1], col = colors, lwd = 2)
colors <- terrain.colors(ncol(coefficients) - 1)  # Generate different colors
# Plot the coefficient paths
plot(log(lambda_values), coefficients[2, ], type = "n", xlab = "Log(Lambda)", ylab = "Coefficients",
main = "Lasso Coefficient Paths Colored by Predictor")
# Add lines for each predictor (starting from 2 because the first is the intercept)
for (i in 2:nrow(coefficients)) {
lines(log(lambda_values), coefficients[i, ], col = colors[i - 1], lwd = 2)
}
# Add a legend to map colors to predictors
legend("topright", legend = rownames(coefficients)[-1], col = colors, lwd = 2)
colors <- terrain.colors(ncol(coefficients) - 1)  # Generate different colors
# Plot the coefficient paths
plot(log(lambda_values), coefficients[2, ], type = "n", xlab = "Log(Lambda)", ylab = "Coefficients",
main = "Lasso Coefficient Paths Colored by Predictor")
# Add lines for each predictor (starting from 2 because the first is the intercept)
for (i in 2:nrow(coefficients)) {
lines(log(lambda_values), coefficients[i, ], col = colors[i - 1], lwd = 2)
}
# Add a legend to map colors to predictors
legend("topright", legend = rownames(coefficients)[-1], col = colors, lwd = 2)
# Define colors for each predictor (excluding the intercept)
colors <- topo.colors(ncol(coefficients) - 1)  # Generate different colors
# Plot the coefficient paths
plot(log(lambda_values), coefficients[2, ], type = "n", xlab = "Log(Lambda)", ylab = "Coefficients",
main = "Lasso Coefficient Paths Colored by Predictor")
# Add lines for each predictor (starting from 2 because the first is the intercept)
for (i in 2:nrow(coefficients)) {
lines(log(lambda_values), coefficients[i, ], col = colors[i - 1], lwd = 2)
}
# Add a legend to map colors to predictors
legend("topright", legend = rownames(coefficients)[-1], col = colors, lwd = 2)
colors <- heat.colors(ncol(coefficients) - 1)  # Generate different colors
# Plot the coefficient paths
plot(log(lambda_values), coefficients[2, ], type = "n", xlab = "Log(Lambda)", ylab = "Coefficients",
main = "Lasso Coefficient Paths Colored by Predictor")
# Add lines for each predictor (starting from 2 because the first is the intercept)
for (i in 2:nrow(coefficients)) {
lines(log(lambda_values), coefficients[i, ], col = colors[i - 1], lwd = 2)
}
# Add a legend to map colors to predictors
legend("topright", legend = rownames(coefficients)[-1], col = colors, lwd = 2)
f (!requireNamespace("RColorBrewer", quietly = TRUE)) {
if (!requireNamespace("RColorBrewer", quietly = TRUE)) {
install.packages("RColorBrewer")
}
library(RColorBrewer)
library(RColorBrewer)
# Define colors for each predictor (excluding the intercept)
# Choose a color palette from RColorBrewer (e.g., "Set1" for distinct colors)
# Choose a color palette from RColorBrewer (e.g., "Set1" for distinct colors)
colors <- brewer.pal(n = ncol(coefficients) - 1, name = "Set1")
# Plot the coefficient paths
plot(log(lambda_values), coefficients[2, ], type = "n", xlab = "Log(Lambda)", ylab = "Coefficients",
main = "Lasso Coefficient Paths Colored by Predictor")
# Add lines for each predictor (excluding the intercept)
for (i in 2:nrow(coefficients)) {
lines(log(lambda_values), coefficients[i, ], col = colors[i - 1], lwd = 2)
}
# Add a legend to map colors to predictors
legend("topright", legend = rownames(coefficients)[-1], col = colors, lwd = 2)
library(lubridate) # For year() function below
install.packages("lub")
install.packages("lubridate")
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
dat = read.csv("C:\\Users\\Dell\\OneDrive\\Desktop\\gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
View(concrete)
View(dat)
library(forecast)
install.packages("forecast")
library(forecast)
bats_model <- bats(tstrain)
bats_forecast <- forecast(bats_model, h = nrow(testing))
Extract the 95% prediction intervals
lower_bound <- bats_forecast$lower[, 2]
upper_bound <- bats_forecast$upper[, 2]
# Check how many of the actual testing values fall within the 95% prediction intervals
within_bounds <- testing$visitsTumblr >= lower_bound & testing$visitsTumblr <= upper_bound
# Count the number of points within bounds
num_within_bounds <- sum(within_bounds)
num_within_bounds
percentage_within_bounds <- sum(within_bounds) / nrow(testing) * 100
percentage_within_bounds
# Load required libraries
set.seed(3523)
library(AppliedPredictiveModeling)
library(e1071)
library(caret)
# Load the concrete data
data(concrete)
# Create training and testing sets
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain,]
testing = concrete[-inTrain,]
# Set seed and fit the SVM model
set.seed(325)
svm_model <- svm(CompressiveStrength ~ ., data = training)
# Predict on the testing set
predictions <- predict(svm_model, testing)
# Calculate RMSE
rmse <- sqrt(mean((predictions - testing$CompressiveStrength)^2))
print(rmse)
# Load required libraries
set.seed(3523)
library(AppliedPredictiveModeling)
library(e1071)
library(caret)
# Load the concrete data
data(concrete)
# Create training and testing sets
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain,]
testing = concrete[-inTrain,]
# Set seed and fit the SVM model
set.seed(325)
svm_model <- svm(CompressiveStrength ~ ., data = training)
# Predict on the testing set
predictions <- predict(svm_model, testing)
# Calculate RMSE
rmse <- sqrt(mean((predictions - testing$CompressiveStrength)^2))
print(rmse)
knitr::opts_chunk$set(echo = TRUE)
library(rattle)
install.packages("rattle")
library(rattle)
library(caret)
library(rpart)
library(rpart.plot)
library(corrplot)
install.packages("corrplot")
library(rattle)
library(caret)
library(rpart)
library(rpart.plot)
library(corrplot)
library(randomForest)
library(RColorBrewer)
set.seed(56789)
setwd("~/GitHub/Practical-Machine-Learning-Johns-Hopkins-Bloomberg-School-of-Public-Health-Coursera/Project")
setwd("C:\\Users\\Dell\\OneDrive\\GitHub\\Practical-Machine-Learning-Johns-Hopkins-Bloomberg-School-of-Public-Health-Coursera\\Project")
setwd("C:\\Users\\Dell\\OneDrive\\Desktop\\GitHub\\Practical-Machine-Learning-Johns-Hopkins-Bloomberg-School-of-Public-Health-Coursera\\Project")
dir.create("~/GitHub/Practical-Machine-Learning-Johns-Hopkins-Bloomberg-School-of-Public-Health-Coursera/Project", recursive = TRUE)
setwd("~/GitHub/Practical-Machine-Learning-Johns-Hopkins-Bloomberg-School-of-Public-Health-Coursera/Project")
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
dir.create("./data")
}
if (!file.exists(trainFile)) {
download.file(trainUrl, destfile = trainFile, method = "curl")
}
if (!file.exists(testFile)) {
download.file(testUrl, destfile = testFile, method = "curl")
}
rm(trainUrl)
rm(testUrl)
trainRaw <- read.csv(trainFile)
testRaw <- read.csv(testFile)
dim(trainRaw)
dim(testRaw)
rm(trainFile)
rm(testFile)
View(testRaw)
NZV <- nearZeroVar(trainRaw, saveMetrics = TRUE)
head(NZV, 20)
training01 <- trainRaw[, !NZV$nzv]
testing01 <- testRaw[, !NZV$nzv]
dim(training01)
dim(testing01)
rm(trainRaw)
rm(testRaw)
rm(NZV)
head(NZV, 20)
NZV <- nearZeroVar(trainRaw, saveMetrics = TRUE)
trainRaw <- read.csv(trainFile)
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
dir.create("./data")
}
if (!file.exists(trainFile)) {
download.file(trainUrl, destfile = trainFile, method = "curl")
}
if (!file.exists(testFile)) {
download.file(testUrl, destfile = testFile, method = "curl")
}
rm(trainUrl)
rm(testUrl)
trainRaw <- read.csv(trainFile)
testRaw <- read.csv(testFile)
dim(trainRaw)
dim(testRaw)
rm(trainFile)
rm(testFile)
NZV <- nearZeroVar(trainRaw, saveMetrics = TRUE)
head(NZV, 20)
training01 <- trainRaw[, !NZV$nzv]
testing01 <- testRaw[, !NZV$nzv]
dim(training01)
dim(testing01)
rm(trainRaw)
rm(testRaw)
rm(NZV)
head(NZV, 20)
NZV <- nearZeroVar(trainRaw, saveMetrics = TRUE)
trainRaw <- read.csv(trainFile)
library(rattle)
library(caret)
library(rpart)
library(rpart.plot)
library(corrplot)
library(randomForest)
library(RColorBrewer)
setwd("C:\\Users\\Dell\\OneDrive\\Desktop\\GitHub\\Practical-Machine-Learning-Johns-Hopkins-Bloomberg-School-of-Public-Health-Coursera\\Project")
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
dir.create("./data")
}
if (!file.exists(trainFile)) {
download.file(trainUrl, destfile = trainFile, method = "curl")
}
if (!file.exists(testFile)) {
download.file(testUrl, destfile = testFile, method = "curl")
}
rm(trainUrl)
rm(testUrl)
trainRaw <- read.csv(trainFile)
testRaw <- read.csv(testFile)
dim(trainRaw)
dim(testRaw)
rm(trainFile)
rm(testFile)
NZV <- nearZeroVar(trainRaw, saveMetrics = TRUE)
head(NZV, 20)
View(NZV)
View(trainRaw)
head(NZV, 20)
training01 <- trainRaw[, !NZV$nzv]
testing01 <- testRaw[, !NZV$nzv]
dim(training01)
rm(trainRaw)
rm(testRaw)
rm(NZV)
View(testing01)
regex <- grepl("^X|timestamp|user_name", names(training01))
training <- training01[, !regex]
testing <- testing01[, !regex]
View(testing)
training <- training01[, !regex]
testing <- testing01[, !regex]
rm(regex)
rm(training01)
rm(testing01)
dim(training)
dim(testing)
regex <- grepl("^X|timestamp|user_name", names(training01))
regex <- grepl("^X|timestamp|user_name", names(training01))
training <- training01[, !regex]
testing <- testing01[, !regex]
rm(regex)
rm(training01)
rm(testing01)
dim(training)
dim(testing)
View(testing)
cond <- (colSums(is.na(training)) == 0)
training <- training[, cond]
testing <- testing[, cond]
rm(cond)
cond <- (colSums(is.na(training)) == 0)
training <- training[, cond]
testing <- testing[, cond]
rm(cond)
View(testing)
corrplot(cor(training[, -length(names(training))]), method = "color", tl.cex = 0.5)
View(training)
set.seed(56789) # For reproducibile purpose
inTrain <- createDataPartition(training$classe, p = 0.70, list = FALSE)
rm(inTrain)
set.seed(56789) # For reproducibile purpose
inTrain <- createDataPartition(training$classe, p = 0.70, list = FALSE)
validation <- training[-inTrain, ]
training <- training[inTrain, ]
rm(inTrain)
## Partitioning Training Set
we split the cleaned training set into a pure training data set (70%) and a validation data set (30%). We will use the validation data set to conduct cross validation in future steps.
## Data Modelling
### Decision Tree
We fit a predictive model for activity recognition using <b>Decision Tree</b> algorithm.
modelTree <- rpart(classe ~ ., data = training, method = "class")
prp(modelTree)
predictTree <- predict(modelTree, validation, type = "class")
validation
View(validation)
predictTree
View(predictTree)
length(predictTree)
confusionMatrix(validation$classe, predictTree)
predictTree <- predict(modelTree, validation, type = "class")
confusionMatrix(validation$classe, predictTree)
predictTree <- predict(modelTree, validation, type = "class")
confusionMatrix(validation$classe, predictTree)
predictTree <- predict(modelTree, validation, type = "class")
predictTree <- predict(modelTree, validation, type = "class")
